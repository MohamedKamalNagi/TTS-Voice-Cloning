ğŸ™ï¸ Voice Cloning with XTTS v2

This project demonstrates multilingual text-to-speech (TTS) with voice cloning using the Coqui TTS
 library and the XTTS v2 model.

It allows you to:

Clone a voice from a sample audio file (input.wav).

Generate speech in multiple languages.

Save the output to a .wav file.

ğŸš€ Features

âœ… Voice cloning from a reference audio file.

âœ… Support for multilingual TTS.

âœ… GPU acceleration with CUDA if available.

âœ… Save generated speech to an audio file.

ğŸ“¦ Installation

Clone this repository:

git clone https://github.com/your-username/voice-cloning-xtts.git
cd voice-cloning-xtts


Create a virtual environment (recommended):

python -m venv venv
venv\Scripts\activate   # On Windows
source venv/bin/activate   # On Linux/Mac


Install dependencies:

pip install torch torchvision torchaudio
pip install TTS

â–¶ï¸ Usage

Place your reference voice file in the project folder (e.g., input.wav).

Run the script:

python d.py


The cloned speech will be saved as:

output.wav

ğŸ“ Example
tts.tts_to_file(
    text="Hello, this is a voice cloning test. Nice to meet you!",
    file_path="output.wav",
    speaker_wav=["input.wav"],
    language="en",
    split_sentences=True
)

ğŸ“‚ Project Structure
â”œâ”€â”€ d.py              # Main script (voice cloning example)
â”œâ”€â”€ input.wav         # Reference speaker audio (provide your own)
â”œâ”€â”€ output.wav        # Generated speech
â”œâ”€â”€ README.md         # Documentation

âš¡ Notes

Make sure input.wav is a clear voice recording (mono, 16kHz preferred).

Use CUDA for faster inference if available.

You can change language="en" to "ar", "fr", "de", etc.

ğŸ¤ Credits

Coqui TTS

PyTorch
