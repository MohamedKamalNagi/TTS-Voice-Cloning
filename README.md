ğŸ™ï¸ Voice Cloning with XTTS v2








This project demonstrates multilingual text-to-speech (TTS) with voice cloning using the Coqui TTS
 library and the XTTS v2 model.

With just one reference audio sample, you can generate natural-sounding speech in multiple languages.

âœ¨ Features

ğŸ¤ Voice Cloning â€“ Clone a voice from a short audio recording (input.wav).

ğŸŒ Multilingual TTS â€“ Generate speech in English, Arabic, French, German, and more.

âš¡ Fast Inference â€“ Runs on GPU (CUDA) if available.

ğŸ’¾ File Output â€“ Save generated audio directly as .wav.

ğŸ“‚ Project Structure
voice-cloning-xtts/
â”‚â”€â”€ Voice_Cloning.py              # Main script (voice cloning example)
â”‚â”€â”€ input.wav         # Reference audio (speaker voice sample)
â”‚â”€â”€ output.wav        # Generated speech
â”‚â”€â”€ requirements.txt  # Dependencies
â”‚â”€â”€ README.md         # Documentation

ğŸ“¦ Installation
1ï¸âƒ£ Clone this repo
git clone (https://github.com/MohamedKamalNagi/TTS-Voice-Cloning)
cd voice-cloning-xtts

2ï¸âƒ£ Create a virtual environment
python -m venv venv
venv\Scripts\activate   # On Windows
source venv/bin/activate   # On Linux/Mac

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

â–¶ï¸ Usage

Place your reference audio as input.wav in the project folder.

Use a clear recording (mono, 16kHz preferred).

Run the script:

python Voice_Cloning.py


The generated cloned voice will be saved as:

output.wav

ğŸ“ Example Code
tts.tts_to_file(
    text="Hello, this is a voice cloning test. Nice to meet you!",
    file_path="output.wav",
    speaker_wav=["input.wav"],
    language="en",
    split_sentences=True
)


You can change the language by modifying language="en" to "ar", "fr", "de", etc.

âš¡ Tips

âœ… Use CUDA GPU if available (device = "cuda") for faster generation.

âœ… Test different reference audios for better cloning quality.

âœ… Try longer texts with split_sentences=True for smoother audio.

ğŸ¤ Credits

Coqui TTS

PyTorch
